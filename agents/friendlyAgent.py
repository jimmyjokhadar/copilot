import os
import logging
from dotenv import load_dotenv
from langchain_ollama import ChatOllama
from prompts.friendly_prompt import friendly_prompt

load_dotenv()
logger = logging.getLogger(__name__)

class FriendlyAgent:
    """
    An agent designed to provide friendly and engaging responses using LLMs.
    1. Initializes with a specified model and temperature.
    2. Builds prompts based on user input.
    3. Generates responses using the LLM.
    4. Provides an invoke method to process state dictionaries.
    """
    def __init__(self, model_name: str = None, temperature: float = 0.8):
        model_name = model_name or os.getenv("MODEL_NAME")
        logger.debug(f"Initializing FriendlyAgent with model: {model_name}")
        if not model_name:
            logger.error("MODEL_NAME environment variable is not set.")
            raise RuntimeError("MODEL_NAME is missing")

        self.llm = ChatOllama(
            model=model_name,
            temperature=temperature
        )

    def respond(self, user_input: str) -> str:
        """
        Generates a friendly response based on user input.
        Args:
            user_input (str): The input from the user.
        Returns:
            str: The friendly response generated by the LLM.
        """
        prompt = self.friendly_prompt(user_input)
        response = self.llm.invoke(prompt)
        return response.content.strip()

    def invoke(self, state: dict) -> dict:
        """
        Processes the input state and generates a friendly response.
        Args:
            state (dict): A dictionary containing 'user_input'.
        Returns:
            dict: A dictionary with the generated response under 'messages'.
        """
        user_input = state.get("user_input")
        if not user_input:
            logger.error("State missing 'user_input'")
            raise ValueError("state missing 'user_input'")
        
        answer = self.respond(user_input)
        logger.debug(f"FriendlyAgent response: {answer}")
        return {
            "messages": [
                {"content": answer}
            ]
        }

